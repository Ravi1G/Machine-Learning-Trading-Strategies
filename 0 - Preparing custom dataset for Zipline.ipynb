{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# How to setup Zipline backtester with custom data from FXCM  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Install standard packages\n",
    "ou should be able to install zipline by using pip. If it doesn't work, there are other ways to install zipline that you can look up.  \n",
    "\n",
    "```\n",
    "pip install zipline\n",
    "```\n",
    "I had to upgrade some packages\n",
    "```\n",
    "pip install -U pip\n",
    "pip install -U numpy\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Download custom forex calendar  \n",
    "Zipline has made its calendars a standalone package available at https://github.com/quantopian/trading_calendars  \n",
    "to make it more available for adding custom calendars, which is what you want because Zipline doesn't support the 24/7 forex calendar as default.  \n",
    "\n",
    "Clone my fork of `trading_calendars` into any preferable location  \n",
    "```\n",
    "git clone https://github.com/grananqvist/trading_calendars.git  \n",
    "```\n",
    "This fork as a new calendar called `forex`  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.  Download my zipline utilities  \n",
    "Necessary utilities are located in zipline_extensions in this repo, download them by cloning the repo into preferable location  \n",
    "```\n",
    "git glone https://github.com/grananqvist/Machine-Learning-Trading-Strategies.git\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Add packages to PYTHONPATH\n",
    "For python to find the repos above, add them to your `$PYTHONPATH` \n",
    "```\n",
    "export PYTHONPATH=$PYTHONPATH:<path-to-trading_calendars>:<path-to-trading-repo>\n",
    "```\n",
    "In my case, my `$PYTHONPATH` looks like this  \n",
    "`/Users/system/Github/Machine-Learning-Trading-Strategies/:/Users/system/Github/trading_calendars/`  \n",
    "\n",
    "Test if packages are installed correctly (you will need to restart the jupyter notebook kernel):  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from zipline.utils.calendars import get_calendar\n",
    "get_calendar('forex')\n",
    "from zipline_extensions.bundles.fxcm import via_fxcm_csv_daily"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Download FXCM data  \n",
    "1. Clone my FXCM data downloader\n",
    "```\n",
    "git clone https://github.com/grananqvist/FXCM-Forex-Data-Downloader.git\n",
    "```\n",
    "2. Get an [API key](https://www.fxcm.com/uk/algorithmic-trading/api-trading/) from FXCM, works with a demo account  \n",
    "3. Download data using the download script  \n",
    "```\n",
    "python main.py -pe D1 -t <YOUR FXCM API KEY> -p <ANY LOCATION TO STORE DATA>\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Edit your extensions.py\n",
    "A file called `extensions.py` should be located in `~/.zipline/`  \n",
    "Insert the code below into `extensions.py` to register fxcm_daily as a bundle for zipline  \n",
    "\n",
    "**Note:** replace `DATA_PATH` with the path to your downloaded dataset  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import os\n",
    "from zipline.data.bundles import register\n",
    "from zipline_extensions.bundles.fxcm import via_fxcm_csv_daily\n",
    "DATA_PATH = os.path.join(\n",
    "    os.environ['HOME'], 'Github/Machine-Learning-Trading-Strategies/data/D1/')\n",
    "\n",
    "register('fxcm_daily', via_fxcm_csv_daily(DATA_PATH), calendar_name='forex')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%load_ext zipline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy  as np\n",
    "import pandas as pd\n",
    "import datetime\n",
    "from zipline.utils.cli import maybe_show_progress\n",
    "\n",
    "def via_fxcm_csv(path,start=None,end=None):\n",
    "    boDebug = True\n",
    "\n",
    "    _, _, file_names = list(os.walk(path))[0]\n",
    "    symbols = [ file_name.split('_')[0] for file_name in file_names ]\n",
    "    tuSymbols = tuple(symbols)\n",
    "\n",
    "    if boDebug:\n",
    "        print( \"entering via_fxcm_csv.  tuSymbols=\",tuSymbols)\n",
    "\n",
    "    # Define our custom ingest function\n",
    "    def ingest(environ,\n",
    "               asset_db_writer,\n",
    "               minute_bar_writer,  # unused\n",
    "               daily_bar_writer,\n",
    "               adjustment_writer,\n",
    "               calendar,\n",
    "               cache,\n",
    "               show_progress,\n",
    "               output_dir,\n",
    "               # pass these as defaults to make them 'nonlocal' in py2\n",
    "               start=start,\n",
    "               end=end):\n",
    "\n",
    "        if boDebug:\n",
    "            print( \"entering ingest and creating blank dfMetadata\")\n",
    "\n",
    "        dfMetadata = pd.DataFrame(np.empty(len(tuSymbols), dtype=[\n",
    "            ('start_date', 'datetime64[ns]'),\n",
    "            ('end_date', 'datetime64[ns]'),\n",
    "            ('auto_close_date', 'datetime64[ns]'),\n",
    "            ('symbol', 'object'),\n",
    "        ]))\n",
    "\n",
    "        if boDebug:\n",
    "            print( \"dfMetadata\",type(dfMetadata))\n",
    "            print( dfMetadata.describe)\n",
    "\n",
    "        # We need to feed something that is iterable - like a list or a generator -\n",
    "        # that is a tuple with an integer for sid and a DataFrame for the data to\n",
    "        # daily_bar_writer\n",
    "\n",
    "        liData=[]\n",
    "        iSid=0\n",
    "        for file_name in file_names:\n",
    "            symbol = file_name.split('_')[0]\n",
    "            if boDebug:\n",
    "               print( \"symbol=\",symbol,\"file=\",file_name)\n",
    "            dfData=pd.read_csv(file_name,index_col='date',parse_dates=True).sort_index()\n",
    "            if boDebug:\n",
    "               print( \"read_csv dfData\",type(dfData),\"length\",len(dfData))\n",
    "            dfData['open'] = (dfData['bidopen'] + dfData['askopen']) / 2\n",
    "            dfData.drop(['bidopen', 'askopen'])\n",
    "            dfData['high'] = (dfData['bidhigh'] + dfData['askhigh']) / 2\n",
    "            dfData.drop(['bidhigh', 'askhigh'])\n",
    "            dfData['low'] = (dfData['bidlow'] + dfData['asklow']) / 2\n",
    "            dfData.drop(['bidlow', 'asklow'])\n",
    "            dfData['close'] = (dfData['bidclose'] + dfData['askclose']) / 2\n",
    "            dfData.drop(['bidclose', 'askclose'])\n",
    "            \"\"\"\n",
    "            dfData.rename(\n",
    "                columns={\n",
    "                    'Open': 'open',\n",
    "                    'High': 'high',\n",
    "                    'Low': 'low',\n",
    "                    'Close': 'close',\n",
    "                    'Volume': 'volume',\n",
    "                    'Adj Close': 'price',\n",
    "                },\n",
    "                inplace=True,\n",
    "            )\n",
    "            \"\"\"\n",
    "            #dfData['volume']=dfData['volume']/1000\n",
    "            liData.append((iSid,dfData))\n",
    "\n",
    "            # the start date is the date of the first trade and\n",
    "            start_date = dfData.index[0]\n",
    "            if boDebug:\n",
    "                print( \"start_date\",type(start_date),start_date)\n",
    "\n",
    "            # the end date is the date of the last trade\n",
    "            end_date = dfData.index[-1]\n",
    "            if boDebug:\n",
    "                print( \"end_date\",type(end_date),end_date)\n",
    "\n",
    "            # The auto_close date is the day after the last trade.\n",
    "            ac_date = end_date + pd.Timedelta(days=1)\n",
    "            if boDebug:\n",
    "                print( \"ac_date\",type(ac_date),ac_date)\n",
    "\n",
    "            # Update our meta data\n",
    "            dfMetadata.iloc[iSid] = start_date, end_date, ac_date, symbol\n",
    "\n",
    "            iSid += 1\n",
    "\n",
    "        if boDebug:\n",
    "            print( \"liData\",type(liData),\"length\",len(liData))\n",
    "            print( liData)\n",
    "            print( \"Now calling daily_bar_writer\")\n",
    "\n",
    "        daily_bar_writer.write(liData, show_progress=False)\n",
    "\n",
    "        dfMetadata['exchange'] = \"FXCM\"\n",
    "\n",
    "        if boDebug:\n",
    "            print( \"returned from daily_bar_writer\")\n",
    "            print( \"calling asset_db_writer\")\n",
    "            print( \"dfMetadata\",type(dfMetadata))\n",
    "            print( dfMetadata)\n",
    "\n",
    "        # Not sure why symbol_map is needed\n",
    "        symbol_map = pd.Series(dfMetadata.symbol.index, dfMetadata.symbol)\n",
    "        if boDebug:\n",
    "            print( \"symbol_map\",type(symbol_map))\n",
    "            print( symbol_map)\n",
    "\n",
    "        asset_db_writer.write(equities=dfMetadata)\n",
    "\n",
    "        if boDebug:\n",
    "            print( \"returned from asset_db_writer\")\n",
    "            print( \"calling adjustment_writer\")\n",
    "\n",
    "        adjustment_writer.write()\n",
    "\n",
    "        if boDebug:\n",
    "            print( \"returned from adjustment_writer\")\n",
    "            print( \"now leaving ingest function\")\n",
    "\n",
    "    if boDebug:\n",
    "       print( \"about to return ingest function\")\n",
    "    return ingest\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "entering via_fxcm_csv.  tuSymbols= ('EURUSD', 'GER30', 'NAS100', 'SPX500', 'US30')\n",
      "about to return ingest function\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda/lib/python3.5/site-packages/ipykernel_launcher.py:6: UserWarning: Overwriting bundle with name 'fxcm_test'\n",
      "  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error: No bundle registered with the name 'fxcm_test'\r\n"
     ]
    }
   ],
   "source": [
    "from zipline.data.bundles import register\n",
    "DATA_PATH = './data/D1/'\n",
    "\n",
    "register(\n",
    "    'fxcm_test',    # name this whatever you like\n",
    "    via_fxcm_csv(DATA_PATH),\n",
    ")\n",
    "!zipline ingest -b fxcm_test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Installation\n",
    "1. install zipline\n",
    "2. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load m1 data "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "df=pd.read_csv(\n",
    "    './data/m1/EURUSD_m1.csv',\n",
    "                    index_col='date',\n",
    "                    parse_dates=True,\n",
    "                    ).sort_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'df' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-4-23be819f822e>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      7\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mdf\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 9\u001b[0;31m \u001b[0mdf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbidask_to_ohlc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdf\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'df' is not defined"
     ]
    }
   ],
   "source": [
    "def bidask_to_ohlc(df):\n",
    "    df['open'] = (df['bidopen'] + df['askopen']) / 2\n",
    "    df['high'] = (df['bidhigh'] + df['askhigh']) / 2\n",
    "    df['low'] = (df['bidlow'] + df['asklow']) / 2\n",
    "    df['close'] = (df['bidclose'] + df['askclose']) / 2\n",
    "    df = df[['open', 'high', 'low', 'close']]\n",
    "    return df\n",
    "\n",
    "df = bidask_to_ohlc(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df = df.resample(\"1min\").mean()\n",
    "df.fillna(method=\"ffill\", inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DatetimeIndex(['2001-11-28 04:14:00', '2001-11-28 04:15:00',\n",
      "               '2001-11-28 04:16:00', '2001-11-28 04:17:00',\n",
      "               '2001-11-28 04:18:00', '2001-11-28 04:19:00',\n",
      "               '2001-11-28 04:20:00', '2001-11-28 04:21:00',\n",
      "               '2001-11-28 04:22:00', '2001-11-28 04:23:00',\n",
      "               ...\n",
      "               '2018-08-29 07:40:00', '2018-08-29 07:41:00',\n",
      "               '2018-08-29 07:42:00', '2018-08-29 07:43:00',\n",
      "               '2018-08-29 07:44:00', '2018-08-29 07:45:00',\n",
      "               '2018-08-29 07:46:00', '2018-08-29 07:47:00',\n",
      "               '2018-08-29 07:48:00', '2018-08-29 07:49:00'],\n",
      "              dtype='datetime64[ns]', name='date', length=8810136, freq='T')\n",
      "                         open      high       low     close\n",
      "date                                                       \n",
      "2001-11-28 04:14:00  0.884895  0.885195  0.884695  0.884695\n",
      "2001-11-28 04:15:00  0.884695  0.884895  0.884495  0.884495\n",
      "2001-11-28 04:16:00  0.884695  0.884895  0.884495  0.884495\n",
      "2001-11-28 04:17:00  0.884495  0.884695  0.884495  0.884495\n",
      "2001-11-28 04:18:00  0.884495  0.884695  0.884495  0.884495\n"
     ]
    }
   ],
   "source": [
    "print(df.index)\n",
    "print(df.head())\n",
    "df.to_csv('./data/m1/EURUSD_m1_cleaned.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda/lib/python3.5/site-packages/ipykernel_launcher.py:2: FutureWarning: how in .resample() is deprecated\n",
      "the new syntax is .resample(...)..apply(<func>)\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>low</th>\n",
       "      <th>high</th>\n",
       "      <th>open</th>\n",
       "      <th>close</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>date</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2001-11-28</th>\n",
       "      <td>0.882795</td>\n",
       "      <td>0.888595</td>\n",
       "      <td>0.884895</td>\n",
       "      <td>0.888095</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2001-11-29</th>\n",
       "      <td>0.885795</td>\n",
       "      <td>0.891895</td>\n",
       "      <td>0.887595</td>\n",
       "      <td>0.887895</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2001-11-30</th>\n",
       "      <td>0.884895</td>\n",
       "      <td>0.898295</td>\n",
       "      <td>0.887295</td>\n",
       "      <td>0.896695</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2001-12-02</th>\n",
       "      <td>0.896595</td>\n",
       "      <td>0.896595</td>\n",
       "      <td>0.896595</td>\n",
       "      <td>0.896595</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2001-12-03</th>\n",
       "      <td>0.889195</td>\n",
       "      <td>0.896895</td>\n",
       "      <td>0.896495</td>\n",
       "      <td>0.891795</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 low      high      open     close\n",
       "date                                              \n",
       "2001-11-28  0.882795  0.888595  0.884895  0.888095\n",
       "2001-11-29  0.885795  0.891895  0.887595  0.887895\n",
       "2001-11-30  0.884895  0.898295  0.887295  0.896695\n",
       "2001-12-02  0.896595  0.896595  0.896595  0.896595\n",
       "2001-12-03  0.889195  0.896895  0.896495  0.891795"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ohlc_dict = {'open':'first', 'high':'max', 'low':'min', 'close': 'last'}\n",
    "df = df.resample(\"24h\", base=21, how=ohlc_dict).dropna(how='any')\n",
    "df.index = df.index + df.index.map(lambda x: pd.Timedelta(hours=3))\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "low      float64\n",
      "high     float64\n",
      "open     float64\n",
      "close    float64\n",
      "dtype: object\n",
      "                 low      high      open     close\n",
      "date                                              \n",
      "2001-11-28  0.882795  0.888595  0.884895  0.888095\n",
      "2001-11-29  0.885795  0.891895  0.887595  0.887895\n",
      "2001-11-30  0.884895  0.898295  0.887295  0.896695\n",
      "2001-12-02  0.896595  0.896595  0.896595  0.896595\n",
      "2001-12-03  0.889195  0.896895  0.896495  0.891795\n",
      "                 low      high      open     close\n",
      "date                                              \n",
      "2018-08-23  1.152980  1.159975  1.159680  1.153920\n",
      "2018-08-24  1.153485  1.163990  1.153920  1.162155\n",
      "2018-08-27  1.159455  1.169370  1.162435  1.167755\n",
      "2018-08-28  1.166250  1.173355  1.167755  1.169430\n",
      "2018-08-29  1.166685  1.169760  1.169440  1.167125\n",
      "DatetimeIndex(['2001-11-28', '2001-11-29', '2001-11-30', '2001-12-02',\n",
      "               '2001-12-03', '2001-12-04', '2001-12-05', '2001-12-06',\n",
      "               '2001-12-07', '2001-12-09',\n",
      "               ...\n",
      "               '2018-08-17', '2018-08-19', '2018-08-20', '2018-08-21',\n",
      "               '2018-08-22', '2018-08-23', '2018-08-24', '2018-08-27',\n",
      "               '2018-08-28', '2018-08-29'],\n",
      "              dtype='datetime64[ns]', name='date', length=4983, freq=None)\n"
     ]
    }
   ],
   "source": [
    "print(df.dtypes)\n",
    "print(df.head())\n",
    "print(df.tail())\n",
    "print(df.index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df.to_csv('./data/D1/EURUSD_D1.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%load_ext zipline\n",
    "import pandas as pd\n",
    "from trading_calendars.calendar_forex import ForexCalendar"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_daily =pd.read_csv(\n",
    "    '../FXCM-Data-Downloader/AUDCAD_D1.csv',\n",
    "                    index_col='date',\n",
    "                    parse_dates=True,\n",
    "                    ).sort_index() \n",
    "df_daily = df_daily.resample(\"1D\").mean()\n",
    "df_daily = bidask_to_ohlc(df_daily)\n",
    "df_daily.fillna(method=\"ffill\", inplace=True)\n",
    "calendar = ForexCalendar()\n",
    "df_daily = calendar.filter_dates(df_daily)\n",
    "#print(df_daily.loc[df.index])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                open      high       low     close\n",
      "2018-07-29  0.966130  0.966200  0.965395  0.965985\n",
      "2018-07-30  0.965995  0.967465  0.962630  0.965615\n",
      "2018-07-31  0.965615  0.970865  0.964805  0.965865\n",
      "2018-08-01  0.965865  0.966840  0.961035  0.962860\n",
      "2018-08-02  0.962860  0.963715  0.958330  0.958485\n",
      "2018-08-03  0.958485  0.962580  0.957870  0.961330\n",
      "2018-08-05  0.961690  0.961705  0.961210  0.961360\n",
      "2018-08-06  0.961360  0.963120  0.960405  0.960555\n",
      "2018-08-07  0.960545  0.970160  0.959945  0.968640\n",
      "2018-08-08  0.968645  0.970690  0.966425  0.967765\n",
      "2018-08-09  0.967765  0.969380  0.961775  0.962215\n",
      "2018-08-10  0.962215  0.962750  0.952810  0.959480\n",
      "2018-08-12  0.957270  0.959715  0.954420  0.957810\n",
      "2018-08-13  0.957800  0.959165  0.953770  0.954965\n",
      "2018-08-14  0.954965  0.955400  0.945030  0.945670\n",
      "2018-08-15  0.945665  0.952490  0.941795  0.951365\n",
      "2018-08-16  0.951375  0.957050  0.948955  0.955205\n",
      "2018-08-17  0.955200  0.957395  0.950810  0.955440\n",
      "2018-08-19  0.954790  0.955915  0.954550  0.955665\n",
      "2018-08-20  0.955660  0.957785  0.953440  0.957600\n",
      "2018-08-21  0.957605  0.961265  0.955945  0.960490\n",
      "2018-08-22  0.960485  0.960910  0.954800  0.955225\n",
      "2018-08-23  0.955235  0.956010  0.947420  0.948095\n",
      "2018-08-24  0.948095  0.956475  0.947560  0.954440\n",
      "2018-08-26  0.948095  0.956475  0.947560  0.954440\n",
      "2018-08-27  0.952395  0.955780  0.951540  0.953310\n",
      "2018-08-28  0.953305  0.953550  0.948125  0.949005\n",
      "2018-08-29  0.949015  0.949665  0.941975  0.943585\n",
      "2018-08-30  0.943585  0.946840  0.940115  0.943095\n",
      "2018-08-31  0.943095  0.944640  0.936295  0.938060\n"
     ]
    }
   ],
   "source": [
    "print(df_daily.tail(30))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DatetimeIndex(['2018-05-08', '2018-05-09', '2018-05-10', '2018-05-11',\n",
      "               '2018-05-13', '2018-05-14', '2018-05-15', '2018-05-16',\n",
      "               '2018-05-17', '2018-05-18', '2018-05-20', '2018-05-21',\n",
      "               '2018-05-22', '2018-05-23', '2018-05-24', '2018-05-25',\n",
      "               '2018-05-27', '2018-05-28', '2018-05-29', '2018-05-30',\n",
      "               '2018-05-31', '2018-06-01', '2018-06-03', '2018-06-04',\n",
      "               '2018-06-05', '2018-06-06', '2018-06-07', '2018-06-08',\n",
      "               '2018-06-10', '2018-06-11', '2018-06-12', '2018-06-13',\n",
      "               '2018-06-14', '2018-06-15', '2018-06-17', '2018-06-18',\n",
      "               '2018-06-19', '2018-06-20', '2018-06-21', '2018-06-22',\n",
      "               '2018-06-24', '2018-06-25', '2018-06-26', '2018-06-27',\n",
      "               '2018-06-28', '2018-06-29', '2018-07-01', '2018-07-02',\n",
      "               '2018-07-03', '2018-07-04', '2018-07-05', '2018-07-06',\n",
      "               '2018-07-08', '2018-07-09', '2018-07-10', '2018-07-11',\n",
      "               '2018-07-12', '2018-07-13', '2018-07-15', '2018-07-16',\n",
      "               '2018-07-17', '2018-07-18', '2018-07-19', '2018-07-20',\n",
      "               '2018-07-22', '2018-07-23', '2018-07-24', '2018-07-25',\n",
      "               '2018-07-26', '2018-07-27', '2018-07-29', '2018-07-30',\n",
      "               '2018-07-31', '2018-08-01', '2018-08-02', '2018-08-03',\n",
      "               '2018-08-05', '2018-08-06', '2018-08-07', '2018-08-08',\n",
      "               '2018-08-09', '2018-08-10', '2018-08-12', '2018-08-13',\n",
      "               '2018-08-14', '2018-08-15', '2018-08-16', '2018-08-17',\n",
      "               '2018-08-19', '2018-08-20', '2018-08-21', '2018-08-22',\n",
      "               '2018-08-23', '2018-08-24', '2018-08-26', '2018-08-27',\n",
      "               '2018-08-28', '2018-08-29', '2018-08-30', '2018-08-31'],\n",
      "              dtype='datetime64[ns]', freq='C')\n"
     ]
    }
   ],
   "source": [
    "print(trading_dates[-100:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
